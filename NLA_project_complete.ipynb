{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLA_project_complete.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHcbHozL5E6W",
        "colab_type": "code",
        "outputId": "5bab179e-3543-4c91-a1d3-143f603bc0f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import MNIST\n",
        "import torch.nn as nn\n",
        "import time\n",
        "\n",
        "\n",
        "# ---------------------------------- Hessian-vector product operator----------------------------------\n",
        "\n",
        "class Operator():\n",
        "    def __init__(self, size):\n",
        "        self._size = size\n",
        "\n",
        "    def apply(self, vec):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def __matmul__(self, vec):\n",
        "        return self.apply(vec)\n",
        "\n",
        "    def size(self):\n",
        "        return self._size\n",
        "\n",
        "\n",
        "class ModelHessianOperator(Operator):\n",
        "    def __init__(self, model, criterion, data_input, data_target):\n",
        "        size = int(sum(p.numel() for p in model.parameters()))\n",
        "        super(ModelHessianOperator, self).__init__(size)\n",
        "        self._model = model\n",
        "        self._criterion = criterion\n",
        "        self.set_model_data(data_input, data_target)\n",
        "\n",
        "    def apply(self, vec):\n",
        "        return to_vector(torch.autograd.grad(self._grad, self._model.parameters()\n",
        "                                             , grad_outputs=vec, only_inputs=True, retain_graph=True))\n",
        "\n",
        "    def set_model_data(self, data_input, data_target):\n",
        "        self._data_input = data_input\n",
        "        self._data_target = data_target\n",
        "        self._output = self._model(self._data_input)\n",
        "        self._loss = self._criterion(self._output, self._data_target)\n",
        "        self._grad = to_vector(torch.autograd.grad(self._loss, self._model.parameters(), create_graph=True))\n",
        "\n",
        "    def get_input(self):\n",
        "        return self._data_input\n",
        "\n",
        "    def get_target(self):\n",
        "        return self._data_target\n",
        "\n",
        "\n",
        "def to_vector(tensors):\n",
        "    return torch.cat([t.contiguous().view(-1) for t in tensors])\n",
        "\n",
        "\n",
        "# ----------------------------------- slq_upd.py -----------------------------------\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from scipy.sparse.linalg import LinearOperator as ScipyLinearOperator\n",
        "# from scipy.sparse.linalg import eigsh\n",
        "# from warnings import warn\n",
        "import scipy.sparse as sps\n",
        "\n",
        "\n",
        "def _lanczos_m_upd(A, m, matrix_shape, nv=1, rademacher=False, SV=None):\n",
        "    orthtol = 1e-2\n",
        "\n",
        "    if type(SV) != np.ndarray:\n",
        "        if rademacher:\n",
        "            # SV = np.sign(np.random.randn(A.shape[0], nv))\n",
        "            SV = np.sign(np.random.randn(matrix_shape[0], nv))\n",
        "        else:\n",
        "            # SV = np.random.randn(A.shape[0], nv)  # init random vectors in columns: n x nv\n",
        "            SV = np.random.randn(matrix_shape[0], nv)\n",
        "\n",
        "    V = np.zeros((SV.shape[0], m, nv))\n",
        "    T = np.zeros((nv, m, m))\n",
        "\n",
        "    np.divide(SV, np.linalg.norm(SV, axis=0), out=SV)  # normalize each column\n",
        "    V[:, 0, :] = SV\n",
        "\n",
        "\n",
        "    w = A.matvec(SV.squeeze())\n",
        "    w = w.reshape(-1,1)\n",
        "    alpha = np.einsum('ij,ij->j', w, SV)\n",
        "    w -= alpha[None, :] * SV\n",
        "    beta = np.einsum('ij,ij->j', w, w)\n",
        "    np.sqrt(beta, beta)\n",
        "\n",
        "    T[:, 0, 0] = alpha\n",
        "    T[:, 0, 1] = beta\n",
        "    T[:, 1, 0] = beta\n",
        "\n",
        "    np.divide(w, beta[None, :], out=w)\n",
        "    V[:, 1, :] = w\n",
        "    t = np.zeros((m, nv))\n",
        "\n",
        "    for i in range(1, m):\n",
        "        SVold = V[:, i - 1, :]\n",
        "        SV = V[:, i, :]\n",
        "\n",
        "        w = A.dot(SV.squeeze())  # sparse @ dense\n",
        "        w = w.reshape(-1, 1)\n",
        "        w -= beta[None, :] * SVold  # n x nv\n",
        "        np.einsum('ij,ij->j', w, SV, out=alpha)\n",
        "\n",
        "        T[:, i, i] = alpha\n",
        "\n",
        "        if i < m - 1:\n",
        "            w -= alpha[None, :] * SV  # n x nv\n",
        "            # reortho\n",
        "            np.einsum('ijk,ik->jk', V, w, out=t)\n",
        "            w -= np.einsum('ijk,jk->ik', V, t)\n",
        "            np.einsum('ij,ij->j', w, w, out=beta)\n",
        "            np.sqrt(beta, beta)\n",
        "            np.divide(w, beta[None, :], out=w)\n",
        "\n",
        "            T[:, i, i + 1] = beta\n",
        "            T[:, i + 1, i] = beta\n",
        "\n",
        "            # more reotho\n",
        "            innerprod = np.einsum('ijk,ik->jk', V, w)\n",
        "            reortho = False\n",
        "            for _ in range(100):\n",
        "                if (innerprod <= orthtol).sum():\n",
        "                    reortho = True\n",
        "                    break\n",
        "                np.einsum('ijk,ik->jk', V, w, out=t)\n",
        "                w -= np.einsum('ijk,jk->ik', V, t)\n",
        "                np.divide(w, np.linalg.norm(w, axis=0)[None, :], out=w)\n",
        "                innerprod = np.einsum('ijk,ik->jk', V, w)\n",
        "\n",
        "            V[:, i + 1, :] = w\n",
        "\n",
        "            if (np.abs(beta) > 1e-2).sum() == 0 or not reortho:\n",
        "                break\n",
        "    return T, V\n",
        "\n",
        "\n",
        "\n",
        "# ------------------------------ lanczos_upd.py ------------------------------\n",
        "\n",
        "def lanczos(\n",
        "    operator,\n",
        "    size,\n",
        "    num_lanczos_vectors,\n",
        "    use_gpu=False,\n",
        "):\n",
        "    shape = (size, size)\n",
        "\n",
        "\n",
        "    def _scipy_apply(x):\n",
        "        x = torch.from_numpy(x)\n",
        "        if use_gpu:\n",
        "            x = x.cuda()\n",
        "        return operator.apply(x.float()).cpu().numpy()\n",
        "\n",
        "    scipy_op = ScipyLinearOperator(shape, _scipy_apply)\n",
        "    T, V = _lanczos_m_upd(A=scipy_op, m=num_lanczos_vectors, matrix_shape=shape, SV=None)\n",
        "    return T, V\n",
        "\n",
        "\n",
        "\n",
        "# ----------------------------------------- Training parameters -----------------------------------------\n",
        "\n",
        "batch_size = 200\n",
        "\n",
        "train_dataset = MNIST(root='MNIST', train=True, transform=transforms.ToTensor(), download=True)\n",
        "test_dataset = MNIST(root='MNIST', train=False, transform=transforms.ToTensor(), download=True)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "n_iters = 500\n",
        "epochs = n_iters / (len(train_dataset) / batch_size)\n",
        "input_dim = 784\n",
        "output_dim = 10\n",
        "lr_rate = 0.001\n",
        "\n",
        "\n",
        "# ----------------------------------------- Logistic Regression -----------------------------------------\n",
        "\n",
        "# class LogisticRegression(torch.nn.Module):\n",
        "#     def __init__(self, input_dim, output_dim):\n",
        "#         super(LogisticRegression, self).__init__()\n",
        "#         self.linear = torch.nn.Linear(input_dim, output_dim)\n",
        "#\n",
        "#     def forward(self, x):\n",
        "#         outputs = self.linear(x)\n",
        "#         return outputs\n",
        "#\n",
        "#\n",
        "# model = LogisticRegression(input_dim, output_dim)\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=lr_rate)\n",
        "#\n",
        "# iter_num = 0\n",
        "# for epoch in range(int(epochs)):\n",
        "#     for i, (images, labels) in enumerate(train_loader):\n",
        "#         images = Variable(images.view(-1, 28 * 28))\n",
        "#         labels = Variable(labels)\n",
        "#\n",
        "#         optimizer.zero_grad()\n",
        "#         outputs = model(images)\n",
        "#         loss = criterion(outputs, labels)\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "#\n",
        "#         iter_num+=1\n",
        "#         if iter_num % 500==0:\n",
        "#             # calculate Accuracy\n",
        "#             correct = 0\n",
        "#             total = 0\n",
        "#             for images, labels in test_loader:\n",
        "#                 images = Variable(images.view(-1, 28*28))\n",
        "#                 outputs = model(images)\n",
        "#                 _, predicted = torch.max(outputs.data, 1)\n",
        "#                 total+= labels.size(0)\n",
        "#                 # for gpu, bring the predicted and labels back to cpu fro python operations to work\n",
        "#                 correct+= (predicted == labels).sum()\n",
        "#             accuracy = 100 * correct/total\n",
        "#             print(\"Iteration: {}. Loss: {}. Accuracy: {}%.\".format(iter_num, loss.item(), accuracy))\n",
        "#\n",
        "# test_batch = next(iter(test_loader))\n",
        "# test_batch[0] = test_batch[0].view(-1, 28 * 28)\n",
        "#\n",
        "# data_input = test_batch[0]\n",
        "# data_target = test_batch[1]\n",
        "# op = ModelHessianOperator(model, criterion, data_input, data_target)\n",
        "# size = to_vector(model.parameters()).shape[0]\n",
        "\n",
        "\n",
        "\n",
        "# ----------------------------------------- ConvNNs -----------------------------------------\n",
        "\n",
        "# model = nn.Sequential(\n",
        "#     nn.Conv2d(1, 8, kernel_size=3),\n",
        "#     nn.ReLU(),\n",
        "#     nn.Conv2d(8, 8, kernel_size=3),\n",
        "#     nn.ReLU(),\n",
        "\n",
        "#     nn.MaxPool2d(2),\n",
        "\n",
        "#     nn.Conv2d(8, 16, kernel_size=3),\n",
        "#     nn.ReLU(),\n",
        "#     nn.Conv2d(16, 16, kernel_size=3),\n",
        "#     nn.ReLU(),\n",
        "\n",
        "#     nn.MaxPool2d(2),\n",
        "#     nn.Flatten(),\n",
        "#     nn.Linear(256, 10),\n",
        "# )\n",
        "\n",
        "\n",
        "def create_model(a, b, c):\n",
        "    return  nn.Sequential(\n",
        "        nn.Conv2d(1, 8, kernel_size=3), # 28 - 2 = 26\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(8, 8, kernel_size=3), # 26 - 2 = 24\n",
        "        nn.ReLU(),\n",
        "\n",
        "        nn.MaxPool2d(2), # 24 / 2 = 12\n",
        "\n",
        "        nn.Conv2d(8, 16, kernel_size=3), # 12 - 2 = 10\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(16, 16, kernel_size=3), # 10 - 2 = 8\n",
        "        nn.ReLU(),\n",
        "\n",
        "        nn.MaxPool2d(2), # 8 / 2 = 4\n",
        "        nn.Flatten(), # nchannels * m * m = 16 * 4 * 4 = 256\n",
        "        nn.Linear(256, a),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(),\n",
        "        nn.Linear(a, b),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(),\n",
        "        nn.Linear(b, c),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(),\n",
        "        nn.Linear(c, 10),\n",
        "    )\n",
        "\n",
        "\n",
        "a_lst = np.arange(25, 100, 5)\n",
        "b_lst = a_lst - 5\n",
        "c_lst = b_lst - 5\n",
        "\n",
        "time_spent_lst = []\n",
        "params_num_lst = []\n",
        "\n",
        "for i in range(len(a_lst)):\n",
        "    a = a_lst[i]\n",
        "    b = b_lst[i]\n",
        "    c = c_lst[i]\n",
        "\n",
        "    print('------------ {}/{} model -------------'. format(i+1, len(a_lst)))\n",
        "    model = create_model(a, b, c)\n",
        "    print('a = {}, b = {}, c = {}'.format(a,b,c))\n",
        "    params_num = sum(p.numel() for p in model.parameters())\n",
        "    print('parameters number: {}'.format(params_num))\n",
        "    params_num_lst.append(params_num)\n",
        "\n",
        "\n",
        "    # model = model.cuda()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=lr_rate)\n",
        "\n",
        "    lr_rate = 0.00007\n",
        "    iter_num = 0\n",
        "    for epoch in range(int(epochs)):\n",
        "        for i, (images, labels) in enumerate(train_loader):\n",
        "            # images = images.cuda()\n",
        "            # labels = labels.cuda()\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            iter_num+=1\n",
        "            if iter_num % 500==0:\n",
        "                # calculate Accuracy\n",
        "                correct = 0\n",
        "                total = 0\n",
        "                for images, labels in test_loader:\n",
        "                    # images = images.cuda()\n",
        "                    # labels = labels.cuda()\n",
        "                    outputs = model(images)\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    total+= labels.size(0)\n",
        "                    # for gpu, bring the predicted and labels back to cpu fro python operations to work\n",
        "                    correct+= (predicted == labels).sum()\n",
        "                accuracy = 100 * correct/total\n",
        "                print(\"Iteration: {}. Loss: {}. Accuracy: {}%.\".format(iter_num, loss.item(), accuracy))\n",
        "\n",
        "    test_batch = next(iter(test_loader))\n",
        "    data_input = test_batch[0]\n",
        "    data_target = test_batch[1]\n",
        "    # op = ModelHessianOperator(model, criterion, data_input.cuda(), data_target.cuda())\n",
        "    op = ModelHessianOperator(model, criterion, data_input, data_target)\n",
        "    size = to_vector(model.parameters()).shape[0]\n",
        "    print ('The model has been trained')\n",
        "\n",
        "    num_lanczos_vectors = int(0.5 * size)\n",
        "    print('Starting Lanczoc method to find {} vectors'.format(num_lanczos_vectors))\n",
        "    start = time.time()\n",
        "    T, V = lanczos(operator=op, num_lanczos_vectors=num_lanczos_vectors, size=size, use_gpu=False)\n",
        "    end = time.time()\n",
        "    print(f'Time spent: {end - start}')\n",
        "    time_spent_lst.append(end - start)\n",
        "    # print(T)\n",
        "    # print(V)\n",
        "\n",
        "\n",
        "\n",
        "# ----------------------------------------- Results downloading -----------------------------------------\n",
        "\n",
        "with open('params_num.txt', 'w') as f:\n",
        "  for item in params_num_lst:\n",
        "    f.write(\"%s\\n\" % item)\n",
        "\n",
        "with open('time_spent.txt', 'w') as f:\n",
        "  for item in time_spent_lst:\n",
        "    f.write(\"%s\\n\" % item)\n",
        "\n",
        "from google.colab import files\n",
        "files.download('params_num.txt')\n",
        "files.download('time_spent.txt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------ 1/15 model -------------\n",
            "a = 25, b = 20, c = 15\n",
            "parameters number: 11572\n",
            "The model has been trained\n",
            "Starting Lanczoc method to find 5786 vectors\n",
            "Time spent: 91.53587698936462\n",
            "------------ 2/15 model -------------\n",
            "a = 30, b = 25, c = 20\n",
            "parameters number: 13367\n",
            "The model has been trained\n",
            "Starting Lanczoc method to find 6683 vectors\n",
            "Time spent: 127.41355729103088\n",
            "------------ 3/15 model -------------\n",
            "a = 35, b = 30, c = 25\n",
            "parameters number: 15262\n",
            "The model has been trained\n",
            "Starting Lanczoc method to find 7631 vectors\n",
            "Time spent: 181.0299243927002\n",
            "------------ 4/15 model -------------\n",
            "a = 40, b = 35, c = 30\n",
            "parameters number: 17257\n",
            "The model has been trained\n",
            "Starting Lanczoc method to find 8628 vectors\n",
            "Time spent: 268.0902545452118\n",
            "------------ 5/15 model -------------\n",
            "a = 45, b = 40, c = 35\n",
            "parameters number: 19352\n",
            "The model has been trained\n",
            "Starting Lanczoc method to find 9676 vectors\n",
            "Time spent: 264.46770763397217\n",
            "------------ 6/15 model -------------\n",
            "a = 50, b = 45, c = 40\n",
            "parameters number: 21547\n",
            "The model has been trained\n",
            "Starting Lanczoc method to find 10773 vectors\n",
            "Time spent: 422.13755345344543\n",
            "------------ 7/15 model -------------\n",
            "a = 55, b = 50, c = 45\n",
            "parameters number: 23842\n",
            "The model has been trained\n",
            "Starting Lanczoc method to find 11921 vectors\n",
            "Time spent: 550.3214616775513\n",
            "------------ 8/15 model -------------\n",
            "a = 60, b = 55, c = 50\n",
            "parameters number: 26237\n",
            "The model has been trained\n",
            "Starting Lanczoc method to find 13118 vectors\n",
            "Time spent: 603.5241429805756\n",
            "------------ 9/15 model -------------\n",
            "a = 65, b = 60, c = 55\n",
            "parameters number: 28732\n",
            "The model has been trained\n",
            "Starting Lanczoc method to find 14366 vectors\n",
            "Time spent: 1005.5611083507538\n",
            "------------ 10/15 model -------------\n",
            "a = 70, b = 65, c = 60\n",
            "parameters number: 31327\n",
            "The model has been trained\n",
            "Starting Lanczoc method to find 15663 vectors\n",
            "Time spent: 1774.0126128196716\n",
            "------------ 11/15 model -------------\n",
            "a = 75, b = 70, c = 65\n",
            "parameters number: 34022\n",
            "The model has been trained\n",
            "Starting Lanczoc method to find 17011 vectors\n",
            "Time spent: 1956.5916664600372\n",
            "------------ 12/15 model -------------\n",
            "a = 80, b = 75, c = 70\n",
            "parameters number: 36817\n",
            "The model has been trained\n",
            "Starting Lanczoc method to find 18408 vectors\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-e3bc17144c6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Starting Lanczoc method to find {} vectors'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_lanczos_vectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m     \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlanczos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_lanczos_vectors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_lanczos_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Time spent: {end - start}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-e3bc17144c6b>\u001b[0m in \u001b[0;36mlanczos\u001b[0;34m(operator, size, num_lanczos_vectors, use_gpu)\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0;31m# vec = np.random.random(size=(shape[0], 1)).astype(float)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;31m# vec = np.random.randn(shape[0], 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m     \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_lanczos_m_upd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscipy_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_lanczos_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSV\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-e3bc17144c6b>\u001b[0m in \u001b[0;36m_lanczos_m_upd\u001b[0;34m(A, m, matrix_shape, nv, rademacher, SV)\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0mw\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mSV\u001b[0m  \u001b[0;31m# n x nv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;31m# reortho\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ijk,ik->jk'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m             \u001b[0mw\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ijk,jk->ik'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ij,ij->j'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36meinsum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/einsumfunc.py\u001b[0m in \u001b[0;36meinsum\u001b[0;34m(*operands, **kwargs)\u001b[0m\n\u001b[1;32m   1354\u001b[0m     \u001b[0;31m# If no optimization, run pure einsum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moptimize_arg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mc_einsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moperands\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m     \u001b[0mvalid_einsum_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'out'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dtype'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'order'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'casting'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dqCKZwFZJaT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}